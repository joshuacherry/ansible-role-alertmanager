---
## General
alertmanager_version: 0.9.1
alertmanager_release_system: linux-amd64
alertmanager_checksum: 407e0311689207b385fb1252f36d3c3119ae9a315e3eba205aaa69d576434ed7

alertmanager_force_reinstall: false

## Service Options

alertmanager_user: prometheus
alertmanager_group: prometheus

# Files & Paths
alertmanager_log_file: "alertmanager.log"
alertmanager_log_path: "/var/log/alertmanager"
alertmanager_root_path: /opt/alertmanager
alertmanager_bin_path: "{{ alertmanager_root_path }}/bin"
alertmanager_data_dir: "{{ alertmanager_root_path }}/data"
alertmanager_config_dir: /etc/alertmanager

# Port & host
alertmanager_port: 9093
alertmanager_external_hostname: "{{ ansible_fqdn }}"

alertmanager_options:
  - "config.file {{ alertmanager_config_dir }}/alertmanager.yml"
  - "storage.path={{ alertmanager_data_dir }}"
  - "web.listen-address=:{{ alertmanager_port }}"
  - "web.external-url=http://{{ alertmanager_external_hostname }}:{{ alertmanager_port }}/"

## Global configuration parameters (https://prometheus.io/docs/alerting/configuration/)

alertmanager_resolve_timeout: 5m

# SMTP
alertmanager_smtp_from: "alertmanager@example.org"
alertmanager_smtp_smarthost: "localhost:25"
alertmanager_smtp_auth_username: "alertmanager"
alertmanager_smtp_auth_password: "password"
alertmanager_smtp_auth_secret: ""
alertmanager_smtp_require_tls: "true"
# Slack
alertmanager_slack_api_url: ""
#PagerDuty
alertmanager_pagerduty_url: ""
#OpsGenie
alertmanager_opsgenie_api_host: ""
# Hipchat
alertmanager_hipchat_url: ""
alertmanager_hipchat_auth_token: ""

alertmanager_conf_routes: |
  # The root route on which each incoming alert enters.
  route:
    # The labels by which incoming alerts are grouped together. For example,
    # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
    # be batched into a single group.
    group_by: ['alertname', 'cluster', 'service']
    
    # When a new group of alerts is created by an incoming alert, wait at
    # least 'group_wait' to send the initial notification.
    # This way ensures that you get multiple alerts for the same group that start
    # firing shortly after another are batched together on the first 
    # notification.
    group_wait: 30s
  
    # When the first notification was sent, wait 'group_interval' to send a batch
    # of new alerts that started firing for that group.
    group_interval: 5m
  
    # If an alert has successfully been sent, wait 'repeat_interval' to
    # resend them.
    repeat_interval: 3h 
  
    # A default receiver
    receiver: team-X-mails
  
    # All the above attributes are inherited by all child routes and can 
    # overwritten on each.
  
    # The child route trees.
    routes:
    # This routes performs a regular expression match on alert labels to
    # catch alerts that are related to a list of services.
    - match_re:
        service: ^(foo1|foo2|baz)$
      receiver: team-X-mails
      # The service has a sub-route for critical alerts, any alerts
      # that do not match, i.e. severity != critical, fall-back to the
      # parent node and are sent to 'team-X-mails'
      routes:
      - match:
          severity: critical
        receiver: team-X-pager
    - match:
        service: files
      receiver: team-Y-mails
  
      routes:
      - match:
          severity: critical
        receiver: team-Y-pager
  
    # This route handles all alerts coming from a database service. If there's
    # no team to handle it, it defaults to the DB team.
    - match:
        service: database
      receiver: team-DB-pager
      # Also group alerts by affected database.
      group_by: [alertname, cluster, database]
      routes:
      - match:
          owner: team-X
        receiver: team-X-pager
      - match:
          owner: team-Y
        receiver: team-Y-pager

alertmanager_conf_inhibit_rules: |
  # Inhibition rules allow to mute a set of alerts given that another alert is
  # firing.
  # We use this to mute any warning-level notifications if the same alert is 
  # already critical.
  inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    # Apply inhibition if the alertname is the same.
    equal: ['alertname', 'cluster', 'service']

alertmanager_conf_receivers: |
  receivers:
  - name: 'team-X-mails'
    email_configs:
    - to: 'team-X+alerts@example.org'
    slack_configs:
    # https://api.slack.com/incoming-webhooks
    - api_url: <API_URL>
      channel: <Channel or user to send notifications>


  - name: 'team-X-pager'
    email_configs:
    - to: 'team-X+alerts-critical@example.org'
    pagerduty_configs:
    - service_key: <team-X-key>

  - name: 'team-Y-mails'
    email_configs:
    - to: 'team-Y+alerts@example.org'

  - name: 'team-Y-pager'
    pagerduty_configs:
    - service_key: <team-Y-key>

  - name: 'team-DB-pager'
    pagerduty_configs:
    - service_key: <team-DB-key>
  - name: 'team-X-hipchat'
    hipchat_configs:
    - auth_token: <auth_token>
      room_id: 85
      message_format: html
      notify: true
